# Backlog

- [x] VS-0001 Scaffold solution structure (single console project + tests) with vertical-slice friendly wiring and DI bootstrap.
  - Created `LORE-LLM.sln` with projects: `src/LORE-LLM` (console app) and `tests/LORE-LLM.Tests` (xUnit).
  - Tests reference `Shouldly`/`NSubstitute`; core references `CSharpFunctionalExtensions`.
  - Added `Directory.Build.props` enforcing nullable reference types, analyzers, and warnings-as-errors (excluding tests).
  - Implemented composition root via `Microsoft.Extensions.Hosting` with DI extension `AddLoreLlmServices` registering the placeholder CLI application.
- [x] VS-0002 Define CLI surface (System.CommandLine) and register initial verbs: `extract`, `augment`, `translate`, `validate`, `integrate`.
  - Each command lives in its own feature module under `Presentation/Commands/<Verb>`.
  - Wire binding models, help text, and minimal handlers returning `Result<int>` via `CSharpFunctionalExtensions`.
  - Root command built with System.CommandLine 2.0 `Parse().InvokeAsync()` flow; stub handlers log intent while returning exit codes.
  - Add unit tests covering command invocation and option parsing.
- [x] VS-0003 Implement raw text extraction pipeline.
  - Added `RawTextExtractor` service + `SourceSegment`/`SourceTextRawDocument` models; command now writes project-scoped `source_text_raw.json` and `workspace.json` with SHA-256 manifest data.
  - Handles ID-only lines by emitting empty segments and skips blank rows; fails gracefully on missing input/no segments.
  - Added integration tests for CLI extract verb plus dedicated unit tests validating JSON/manifest output.
- [x] VS-0004 Define schemas for metadata, clusters, knowledge, and investigation.
  - Add strongly typed records for `SegmentMetadata`, `ClusterContext`, `KnowledgeEntry`, and `InvestigationSuggestion` (linkage between segments and indexed wiki articles).
  - Document JSON schemas in `docs/schemas/` and provide examples in `docs/examples/` for metadata, clusters, wiki knowledge entries, and investigation reports.
  - Build wiki ingestion scaffold using the MediaWiki API (e.g., `action=query&list=allpages`, `prop=extracts|info`) to cache article metadata (title, summary, license, last updated) and produce an investigation report that cross-references segments with wiki suggestions.
  - Ensure serialization tests cover round-trip validation for the new models and their artifacts.
- [x] VS-0005 Introduce post-processing pipeline.
  - Define `IPostExtractionProcessor` (or similar) and register per-project processors via DI/config.
  - Implement Marble Nest processor that removes empty segments or other quest-specific quirks after extraction.
  - Add CLI wiring (e.g., optional `--post-process` flag or default run) and tests verifying processors mutate workspace artifacts correctly.
  - Document processor extension points and add an example config entry in the docs.
- [x] VS-0006 Implement investigation stage.
  - Added `investigate` CLI command that reads `source_text_raw.json`, generates `investigation.json`, and refreshes the workspace manifest.
  - Implemented token heuristics and candidate matching backed by a MediaWiki ingestion service (opensearch + parse) with on-disk caching and knowledge base emission.
  - Investigation workflow now persists `knowledge_base.json`, updates manifest artifacts, and surfaces wiki-backed candidates per segment.
  - Expanded unit and CLI coverage around the pipeline and refreshed docs/examples for the new artifacts.
- [x] VS-0007 Crawl wiki pages to Markdown via API.
  - Implemented `crawl-wiki` CLI command with pluggable `IMediaWikiCrawler`, caching of `allpages`, markdown conversion, throttling, and deterministic tests.
  - Stored outputs under `knowledge/raw/*.md`; seeded Daniil Dankovsky/Bachelor entries as verification.
  - Added HTML post-processing pipeline with project-specific sanitizers that strip wiki UI artifacts and flatten multi-tab layouts into Markdown sections.
- [] VS-0008 MediaWiki crawler post-processing plugins.
  - Introduced configuration-driven HTML pipeline backed by `MediaWikiCrawlerOptions`, letting each sanitized project map to its API base and ordered post-processor list.
  - Added Pathologic-specific processor that strips infoboxes, tab chrome, galleries, and other decorative elements while flattening tabs into Markdown headings.
  - Documented extension guidance in `docs/LORE-LLM_Handbook.md` so new fandoms can register processors through DI without touching core crawler logic.
  - Tab-aware exports now emit only per-variant Markdown when configured (Pathologic disables the combined document via `EmitBaseDocument = false`); follow-up work will slot these into project-specific subfolders and add a CLI indexing command so plugins can emit searchable catalogs.
- [x] VS-0009 LLM-assisted clustering (chat protocol).
  - Introduced `cluster` CLI command with pluggable `IChatProvider` abstraction, `ChatProviderResolver`, and `ClusterWorkflow`.
  - Implemented `local` provider (offline deterministic clustering for testing) and registered via DI.
  - Workflow batches segments, formats Markdown prompts (with optional custom templates via `--prompt-template`), invokes provider, parses JSON response, and maintains `clusters_current.json` plus immutable `clusters_llm_part_*.json` snapshots.
  - Optional `--save-transcript` flag emits `clusters_llm_transcript.md` capturing full prompt/response conversation for auditing.
  - Updates `workspace.json` manifest with `clusters` artifact references.
  - Added CLI integration tests with stub provider validating end-to-end artifact generation and manifest updates.
  - Documented usage in the handbook with practical workflows for Cursor, browser-based chat, and future API providers.
- [x] VS-0010 Pluggable retrieval index pipeline.
  - Added `RetrievalIndexManifest` with provider entries written to `knowledge/index.manifest.json`.
  - Extended `index-wiki` to accept vector flags (`--with-vector`, `--qdrant-endpoint`, `--qdrant-api-key`, `--qdrant-collection`, `--vector-dimension`, `--embedding-source`).
  - Implemented deterministic `HashEmbeddingProvider` and minimal `QdrantClient` (HTTP) to seed a collection with title vectors.
  - Keyword artifact hashing recorded in the manifest; workspace manifest updated with `retrievalIndexManifest`.
  - DI wiring added for embedding provider and Qdrant HttpClient; existing tests remain green.

- [] VS-0011 Post-crawl glossary tagging (Aho–Corasick).
  - After `crawl-wiki` and before indexing, run an Aho–Corasick matcher over raw segments to annotate metadata, e.g., `contains_glossary_terms: ["Mother Boddho", "Executor"]`.
  - Persist per-segment annotations into workspace artifacts to inform investigation, clustering prompts, and glossary enforcement.
  - Add CLI toggle and tests; wire into the pipeline as an optional post-processor.
- [] VS-0012 Enrich Qdrant payloads for deterministic lookups.
  - Extend `WikiIndexService` vector upserts to include markdown slug/relative path plus normalized keyword tokens in each payload.
  - Record the additional metadata in `RetrievalIndexManifest` config so downstream consumers can rely on a single source of truth.
  - Reuse the existing `KnowledgeKeywordIndexEntry.NormalizeToken` output (title-derived tokens) so glossary filters line up without a new tokenizer.
  - Cover the new payload contract with unit tests (index builder + manifest) and refresh documentation examples if shapes change.
  - Manual verification focuses on payload/manifest inspection; end-to-end cluster retrieval waits for VS-0013 and VS-0014.
- [] VS-0013 Qdrant search abstraction with keyword filters.
  - Add a `SearchAsync` method to `QdrantClient` that accepts query vectors, top-k, and optional keyword filters derived from glossary/Aho tagging.
  - Surface a retrieval orchestrator that maps keywords → filter clauses and falls back cleanly when no tags exist.
  - Provide integration tests (stub HTTP) proving filter JSON, error handling, and deterministic ranking behaviour.
- [] VS-0014 Cluster context retrieval powered by Qdrant.
  - Generate per-cluster query embeddings (segment synopsis + metadata) and combine with glossary tokens to drive filtered Qdrant searches.
  - Resolve search hits into concrete markdown paths, persist selected snippets into `cluster_context.json`, and update `workspace.json` manifests.
  - Add coverage that exercises vector + keyword flows end-to-end, including edge cases with empty tags or missing wiki documents.
  - Capture follow-up notes for potential markdown chunk/section embeddings once higher-fidelity models are available.


