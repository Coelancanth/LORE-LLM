# Backlog

- [x] VS-0001 Scaffold solution structure (single console project + tests) with vertical-slice friendly wiring and DI bootstrap.
  - Created `LORE-LLM.sln` with projects: `src/LORE-LLM` (console app) and `tests/LORE-LLM.Tests` (xUnit).
  - Tests reference `Shouldly`/`NSubstitute`; core references `CSharpFunctionalExtensions`.
  - Added `Directory.Build.props` enforcing nullable reference types, analyzers, and warnings-as-errors (excluding tests).
  - Implemented composition root via `Microsoft.Extensions.Hosting` with DI extension `AddLoreLlmServices` registering the placeholder CLI application.
- [x] VS-0002 Define CLI surface (System.CommandLine) and register initial verbs: `extract`, `augment`, `translate`, `validate`, `integrate`.
  - Each command lives in its own feature module under `Presentation/Commands/<Verb>`.
  - Wire binding models, help text, and minimal handlers returning `Result<int>` via `CSharpFunctionalExtensions`.
  - Root command built with System.CommandLine 2.0 `Parse().InvokeAsync()` flow; stub handlers log intent while returning exit codes.
  - Add unit tests covering command invocation and option parsing.
- [x] VS-0003 Implement raw text extraction pipeline.
  - Added `RawTextExtractor` service + `SourceSegment`/`SourceTextRawDocument` models; command now writes project-scoped `source_text_raw.json` and `workspace.json` with SHA-256 manifest data.
  - Handles ID-only lines by emitting empty segments and skips blank rows; fails gracefully on missing input/no segments.
  - Added integration tests for CLI extract verb plus dedicated unit tests validating JSON/manifest output.
- [x] VS-0004 Define schemas for metadata, clusters, knowledge, and investigation.
  - Add strongly typed records for `SegmentMetadata`, `ClusterContext`, `KnowledgeEntry`, and `InvestigationSuggestion` (linkage between segments and indexed wiki articles).
  - Document JSON schemas in `docs/schemas/` and provide examples in `docs/examples/` for metadata, clusters, wiki knowledge entries, and investigation reports.
  - Build wiki ingestion scaffold using the MediaWiki API (e.g., `action=query&list=allpages`, `prop=extracts|info`) to cache article metadata (title, summary, license, last updated) and produce an investigation report that cross-references segments with wiki suggestions.
  - Ensure serialization tests cover round-trip validation for the new models and their artifacts.
- [x] VS-0005 Introduce post-processing pipeline.
  - Define `IPostExtractionProcessor` (or similar) and register per-project processors via DI/config.
  - Implement Marble Nest processor that removes empty segments or other quest-specific quirks after extraction.
  - Add CLI wiring (e.g., optional `--post-process` flag or default run) and tests verifying processors mutate workspace artifacts correctly.
  - Document processor extension points and add an example config entry in the docs.
- [x] VS-0006 Implement investigation stage.
  - Added `investigate` CLI command that reads `source_text_raw.json`, generates `investigation.json`, and refreshes the workspace manifest.
  - Implemented token heuristics and candidate matching backed by a MediaWiki ingestion service (opensearch + parse) with on-disk caching and knowledge base emission.
  - Investigation workflow now persists `knowledge_base.json`, updates manifest artifacts, and surfaces wiki-backed candidates per segment.
  - Expanded unit and CLI coverage around the pipeline and refreshed docs/examples for the new artifacts.
- [x] VS-0007 Crawl wiki pages to Markdown via API.
  - Implemented `crawl-wiki` CLI command with pluggable `IMediaWikiCrawler`, caching of `allpages`, markdown conversion, throttling, and deterministic tests.
  - Stored outputs under `knowledge/raw/*.md`; seeded Daniil Dankovsky/Bachelor entries as verification.
  - Remaining follow-up: strip wiki UI artifacts (tables/infoboxes), add per-project post-processing knobs, and refine multi-tab rendering (tracked under VS-0008).
- [ ] VS-0008 MediaWiki crawler post-processing plugins.
  - Introduce a configurable post-processing pipeline (similar to `IPostExtractionProcessor`) so each project can register site-specific HTML cleanup (e.g., strip infoboxes, game maps, official art galleries).
  - Provide a Pathologic-specific plugin that removes decorative tables, screenshot galleries, and other UI fragments, yielding concise markdown sections per tab.
  - Allow overrides via configuration/DI so additional fandoms can supply their own sanitizers without touching the core crawler.
- [ ] VS-0009 LLM-assisted clustering (chat protocol).
  - Introduce a `cluster` CLI experience that batches segments and formats Markdown prompts for a user-selected chat provider (Cursor, OpenAI, Claude, etc.).
  - Define a lightweight prompt/response contract so the LLM returns structured cluster metadata (`clusterId`, member IDs, synopsis, confidence).
  - Persist results to `clusters_llm.json` alongside the raw conversation transcript for auditing and add integration tests around the new artifact shape.
  - Make the chat provider pluggable (protocol + API key/config inputs) and document usage in onboarding.
- [ ] VS-0010 Glossary-aware enrichment from clusters.
  - Use LLM-generated clusters to detect glossary terms, flag gaps, and push cluster summaries back onto member segments for the augmentation/translation pipeline.
  - Extend augmentation to consume `clusters_llm.json`, merging cluster synopses and glossary highlights into segment metadata.
  - Provide CLI toggles for enabling the enrichment path and update docs/tests to reflect glossary + cluster interplay.


